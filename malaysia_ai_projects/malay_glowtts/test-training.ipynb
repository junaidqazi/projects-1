{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import TextMelLoader, TextMelCollate, symbols\n",
    "from torch.utils.data import DataLoader\n",
    "import models\n",
    "import utils\n",
    "import torch\n",
    "import commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_files': '/home/husein/speech-bahasa/male-train-set.txt', 'validation_files': '/home/husein/speech-bahasa/male-test-set.txt', 'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'add_noise': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hps = utils.get_hparams_from_file('config/base.json')\n",
    "hps.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/malaya/projects/malaysia_ai_projects/malay_glowtts/modules.py:200: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1940.)\n",
      "  w_init = torch.qr(torch.FloatTensor(self.n_split, self.n_split).normal_())[0]\n"
     ]
    }
   ],
   "source": [
    "generator = models.FlowGenerator(\n",
    "  n_vocab=len(symbols) + getattr(hps.data, \"add_blank\", False), \n",
    "  out_channels=hps.data.n_mel_channels, \n",
    "  **hps.model).cuda()\n",
    "optimizer_g = commons.Adam(generator.parameters(), \n",
    "                           scheduler=hps.train.scheduler, dim_model=hps.model.hidden_channels, warmup_steps=hps.train.warmup_steps, \n",
    "                           lr=hps.train.learning_rate, betas=hps.train.betas, eps=hps.train.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextMelLoader(hps.data.training_files, hps.data)\n",
    "collate_fn = TextMelCollate(1)\n",
    "train_loader = DataLoader(train_dataset, num_workers=8, shuffle=False,\n",
    "  batch_size=hps.train.batch_size, pin_memory=True,\n",
    "  drop_last=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TextMelLoader(hps.data.validation_files, hps.data)\n",
    "val_loader = DataLoader(val_dataset, num_workers=8, shuffle=False,\n",
    "                            batch_size=hps.train.batch_size, pin_memory=True,\n",
    "                            drop_last=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = enumerate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_val = enumerate(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx, (x, x_lengths, y, y_lengths) = next(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 80, 689])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([689, 544, 620, 623, 585, 570, 601, 491, 444, 476, 478, 355, 440, 369,\n",
       "        342, 298, 264, 288, 295, 288, 248, 300, 269, 186, 155, 129,  93, 101,\n",
       "         90,  72,  88,  49])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([111, 101,  99,  98,  97,  90,  88,  80,  77,  75,  74,  59,  59,  54,\n",
       "         53,  51,  50,  45,  45,  38,  37,  36,  34,  28,  23,  21,  17,  15,\n",
       "         14,  11,  10,   7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_lengths = x.cuda(non_blocking=True), x_lengths.cuda(non_blocking=True)\n",
    "y, y_lengths = y.cuda(non_blocking=True), y_lengths.cuda(non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlowGenerator(\n",
       "  (encoder): TextEncoder(\n",
       "    (emb): Embedding(34, 192)\n",
       "    (pre): ConvReluNorm(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Conv1d(192, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (1): Conv1d(192, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (2): Conv1d(192, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "      (norm_layers): ModuleList(\n",
       "        (0): LayerNorm()\n",
       "        (1): LayerNorm()\n",
       "        (2): LayerNorm()\n",
       "      )\n",
       "      (relu_drop): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (attn_layers): ModuleList(\n",
       "        (0): MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_1): ModuleList(\n",
       "        (0): LayerNorm()\n",
       "        (1): LayerNorm()\n",
       "        (2): LayerNorm()\n",
       "        (3): LayerNorm()\n",
       "        (4): LayerNorm()\n",
       "        (5): LayerNorm()\n",
       "      )\n",
       "      (ffn_layers): ModuleList(\n",
       "        (0): FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_2): ModuleList(\n",
       "        (0): LayerNorm()\n",
       "        (1): LayerNorm()\n",
       "        (2): LayerNorm()\n",
       "        (3): LayerNorm()\n",
       "        (4): LayerNorm()\n",
       "        (5): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (proj_m): Conv1d(192, 80, kernel_size=(1,), stride=(1,))\n",
       "    (proj_w): DurationPredictor(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (conv_1): Conv1d(192, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm_1): LayerNorm()\n",
       "      (conv_2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm_2): LayerNorm()\n",
       "      (proj): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (decoder): FlowSpecDecoder(\n",
       "    (flows): ModuleList(\n",
       "      (0): ActNorm()\n",
       "      (1): InvConvNear()\n",
       "      (2): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ActNorm()\n",
       "      (4): InvConvNear()\n",
       "      (5): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ActNorm()\n",
       "      (7): InvConvNear()\n",
       "      (8): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): ActNorm()\n",
       "      (10): InvConvNear()\n",
       "      (11): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): ActNorm()\n",
       "      (13): InvConvNear()\n",
       "      (14): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): ActNorm()\n",
       "      (16): InvConvNear()\n",
       "      (17): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): ActNorm()\n",
       "      (19): InvConvNear()\n",
       "      (20): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): ActNorm()\n",
       "      (22): InvConvNear()\n",
       "      (23): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): ActNorm()\n",
       "      (25): InvConvNear()\n",
       "      (26): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): ActNorm()\n",
       "      (28): InvConvNear()\n",
       "      (29): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): ActNorm()\n",
       "      (31): InvConvNear()\n",
       "      (32): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (33): ActNorm()\n",
       "      (34): InvConvNear()\n",
       "      (35): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_g.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "(z, z_m, z_logs, logdet, z_mask), (x_m, x_logs, x_mask), (attn, logw, logw_) = generator(x, x_lengths, y, y_lengths, gen=False)\n",
    "l_mle = commons.mle_loss(z, z_m, z_logs, logdet, z_mask)\n",
    "l_length = commons.duration_loss(logw, logw_, x_lengths)\n",
    "\n",
    "loss_gs = [l_mle, l_length]\n",
    "loss_g = sum(loss_gs)\n",
    "\n",
    "loss_g.backward()\n",
    "grad_norm = commons.clip_grad_value_(generator.parameters(), 5)\n",
    "optimizer_g.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1593, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
